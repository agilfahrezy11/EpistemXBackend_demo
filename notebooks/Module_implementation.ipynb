{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b9b0c0",
   "metadata": {},
   "source": [
    "# Demonstration of EPISTEM-x Module \n",
    "This notebook contain the implementation of the source code for each module in the EPISTEM land cover mapping framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed875980",
   "metadata": {},
   "source": [
    "## Library import and earth engine initialization\n",
    "If you have earth engine account you could used that to authenticate and initialize the earth engine. However, if you did not have the account, service account initialization is avaliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is used if the notebook is implemented in github codespace. Just remove the (#)\n",
    "!python -m pip install .. --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee \n",
    "import epistemx\n",
    "\n",
    "#Option 1: Manual authenticate using personal account\n",
    "#Instructions for manual authentication\n",
    "epistemx.print_auth_instructions()\n",
    "#uncomment the below line and follow earth engine authentication process\n",
    "#epistemx.authenticate_manually()\n",
    "\n",
    "#Option 2: Autheticate using service account (json file)\n",
    "service_account_path = '../auth/ee-rg2icraf-ecab9c534f91.json'\n",
    "success = epistemx.initialize_with_service_account(service_account_path)\n",
    "\n",
    "if success:\n",
    "    print(\"Earth Engine initialized with service account successfully!\")\n",
    "else:\n",
    "    print(\"Service account initialization failed. Try to authenticate earth engine manually\")\n",
    "\n",
    "#Check authentication status\n",
    "status = epistemx.get_auth_status()\n",
    "print(f\"Initialized: {status['initialized']}\")\n",
    "print(f\"Authenticated: {status['authenticated']}\")\n",
    "if status['project']:\n",
    "    print(f\"Project: {status['project']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e17a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "from epistemx.module_1 import Reflectance_Data, Reflectance_Stats\n",
    "from epistemx.helpers import get_aoi_from_gaul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1466e",
   "metadata": {},
   "source": [
    "## Module 1: Acquisition of Near-Cloud-Free Satellite Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114ef38",
   "metadata": {},
   "source": [
    "### System Response 1.1: Area of Interest Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8507432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the country and province for the AOI using GAUL admin boundaries\n",
    "aoi = get_aoi_from_gaul(country=\"Indonesia\", province=\"Sumatera Selatan\")\n",
    "#Alternatively, used geemap_shp_to_ee to directly used shapefile in your local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e3a9f",
   "metadata": {},
   "source": [
    "### System Response 1.2: Search and Filter Imagery\n",
    "The EPISTEM source code supports Landsat mission data, ranging from Landsat 1 to Landsat 9. For Landsat 1 - 3, the avaliable data is corrected radiance reflectance. The Landsat 5-9 used here is collection 2 surface reflectance (SR) analysis ready data.\n",
    "\n",
    "The retrival logic used here is as follow:\n",
    "1. Retrive multispectral bands (band 1 - 7) from landsat collection 2 SR data (if avaliable)\n",
    "2. Retrive thermal band from landsat collection 2 TOA data \n",
    "3. Create temporal composite for each data \n",
    "4. Stacked the final two data into a earth engine image (ee.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3027fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========== FIRST RETRIVE THE MULTISPECTRAL BAND===========\n",
    "#Intialize the relfectance class data function\n",
    "optical_reflectance = Reflectance_Data()\n",
    "#define the start and end date for imagery collection\n",
    "start = '2017-01-01'\n",
    "end = '2017-12-31'\n",
    "#get the image collection and corresponding statistics\n",
    "landsat_data, meta = optical_reflectance.get_optical_data(aoi, start, end, optical_data='L8_SR', \n",
    "                                                           cloud_cover=40, compute_detailed_stats=False)\n",
    "#create mosaic between image collection, and clip based on AOI\n",
    "mosaic_landsat = landsat_data.mosaic().clip(aoi)\n",
    "#Alternatively you can use temporal aggregation (ee reducer) to create mode cloudless imagery\n",
    "median_landsat = landsat_data.median().clip(aoi)\n",
    "#visualization parameter\n",
    "l8_sr_visparam = {'min': 0,'max': 0.4,'gamma': [0.95, 1.1, 1],'bands':['NIR', 'RED', 'GREEN']}\n",
    "#Add the data to the map\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(mosaic_landsat, l8_sr_visparam, 'L8 SR Mosaic')\n",
    "Map.addLayer(median_landsat, l8_sr_visparam, 'L8 SR Median')\n",
    "Map.addLayer(landsat_data, l8_sr_visparam, 'L8 SR Image Collection')\n",
    "# set center of the map in the area of interest\n",
    "Map.centerObject(aoi, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62243459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retive thermal bands from TOA\n",
    "thermal_bands, thermal_stats = optical_reflectance.get_thermal_bands(aoi, start, end, cloud_cover=40, compute_detailed_stats=False)\n",
    "median_thermal = thermal_bands.median().clip(aoi)\n",
    "thermal_vis = {\n",
    "    'min': 286,\n",
    "    'max': 300,\n",
    "    'gammma': 0.4\n",
    "}\n",
    "#stacked all landsat bands\n",
    "stacked_landsat = median_landsat.addBands(median_thermal)\n",
    "#visualize the thermal bands and multispectral bands\n",
    "Map.addLayer(median_thermal, thermal_vis, \"Thermal Bands\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d9542d",
   "metadata": {},
   "source": [
    "### Image retrival report (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcdcd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the statistic class\n",
    "stats = Reflectance_Stats()\n",
    "#get the retrival report and automatically print them\n",
    "retrival_report = stats.get_collection_statistics(landsat_data, print_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb839e51",
   "metadata": {},
   "source": [
    "### System Response 1.3: Imagery Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d212e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_task = ee.batch.Export.image.toDrive(\n",
    "    image=stacked_landsat,\n",
    "    description='Landsat_Median_composite_2017_Sumsel',\n",
    "    folder='Earth Engine',\n",
    "    fileNamePrefix='Landsat_Median_composite_2017_Sumsel',\n",
    "    scale=30,\n",
    "    region=aoi,  # or aoi.geometry()\n",
    "    maxPixels=1e13\n",
    ")\n",
    "export_task.start()\n",
    "import time\n",
    "\n",
    "while export_task.active():\n",
    "    print('Exporting... (status: {})'.format(export_task.status()['state']))\n",
    "    time.sleep(10)\n",
    "\n",
    "print('Export complete (status: {})'.format(export_task.status()['state']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d798e32",
   "metadata": {},
   "source": [
    "## Module 2:  Land-cover classification Scheme\n",
    "Three approach are provided to handle classification scheme:\n",
    "1. Upload a csv file \n",
    "2. Manual input the classification scheme\n",
    "3. Use default classification scheme (RESTORE+ project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534c2be",
   "metadata": {},
   "source": [
    "### Import the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epistemx.module_2 import LULC_Scheme_Manager\n",
    "#Initialize the LULC Scheme Manager\n",
    "manager = LULC_Scheme_Manager()\n",
    "print(\"Land Cover Classification Scheme Manager initialized!\")\n",
    "print(f\"Current class count: {manager.get_class_count()}\")\n",
    "#Temporary function to display the classiifcation scheme in notebook\n",
    "#Display current classification scheme\n",
    "def display_classification_scheme(manager):\n",
    "    \"\"\"Display the current classification scheme in a readable format\"\"\"\n",
    "    if not manager.has_classes():\n",
    "        print(\"No classes defined yet.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n=== Current Classification Scheme ===\")\n",
    "    df = manager.get_dataframe()\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Display the scheme\n",
    "df = display_classification_scheme(manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d08dfb",
   "metadata": {},
   "source": [
    "### System Response 2.1a: Upload Classification Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c972c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Reset manager for CSV upload example\n",
    "manager = LULC_Scheme_Manager()\n",
    "#path to csv \n",
    "csv_path = \"../test_data/Example_Classification_scheme.csv\"\n",
    "\n",
    "print(\"=== CSV Upload Process ===\")\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
    "print(\"Loaded CSV:\")\n",
    "print(df)\n",
    "\n",
    "# Auto-detect columns\n",
    "id_col, name_col, color_col = manager.auto_detect_csv_columns(df)\n",
    "print(f\"\\nAuto-detected columns:\")\n",
    "print(f\"ID column: {id_col}\")\n",
    "print(f\"Name column: {name_col}\")\n",
    "print(f\"Color column: {color_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CSV upload\n",
    "success, message = manager.process_csv_upload(df, id_col, name_col, color_col)\n",
    "if success:\n",
    "    print(f\"✅ {message}\")\n",
    "    \n",
    "    # Finalize the upload\n",
    "    success, message = manager.finalize_csv_upload()\n",
    "    if success:\n",
    "        print(f\"✅ {message}\")\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "else:\n",
    "    print(f\"❌ {message}\")\n",
    "\n",
    "# Display the loaded scheme\n",
    "display_classification_scheme(manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d8b9f",
   "metadata": {},
   "source": [
    "### System Response 2.1b: Manual Scheme Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset manager for manual input example\n",
    "manager = LULC_Scheme_Manager()\n",
    "#Manually add the class\n",
    "print(\"=== Manual Class Addition ===\")\n",
    "\n",
    "#Example of class to add\n",
    "classes_to_add = [\n",
    "    (1, \"Hutan Lahan Kering\", \"#0E6D0E\"),\n",
    "    (2, \"Pertanian Lahan Kering\", \"#E8F800\"),\n",
    "    (3, \"Permukiman\", \"#F81D00\"),\n",
    "    (4, \"Badan Air\", \"#1512F3\"),\n",
    "    (5, \"Pertanian Lahan Basah\", \"#\")\n",
    "]\n",
    "\n",
    "for class_id, class_name, color_code in classes_to_add:\n",
    "    success, message = manager.add_class(class_id, class_name, color_code)\n",
    "    if success:\n",
    "        print(f\"✅ {message}\")\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "\n",
    "print(f\"\\nTotal classes: {manager.get_class_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213558d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Edit an existing class\n",
    "print(\"=== Editing a Class ===\")\n",
    "\n",
    "# Edit the first class (index 0)\n",
    "class_to_edit = manager.edit_class(0)\n",
    "if class_to_edit:\n",
    "    print(f\"Editing class: {class_to_edit}\")\n",
    "    \n",
    "    # Update the class with new information\n",
    "    success, message = manager.add_class(1, \"HUtan Lahan Rendah\", \"#004D00\")\n",
    "    if success:\n",
    "        print(f\"✅ {message}\")\n",
    "    else:\n",
    "        print(f\"❌ {message}\")\n",
    "\n",
    "# Display updated scheme\n",
    "display_classification_scheme(manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704bb924",
   "metadata": {},
   "source": [
    "### System Response 2.1c: Template Classification Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset manager for default scheme example\n",
    "manager = LULC_Scheme_Manager()\n",
    "\n",
    "print(\"=== Available Default Schemes ===\")\n",
    "default_schemes = manager.get_default_schemes()\n",
    "\n",
    "for scheme_name, classes in default_schemes.items():\n",
    "    print(f\"\\n{scheme_name}: {len(classes)} classes\")\n",
    "    for class_data in classes:\n",
    "        print(f\"  - ID {class_data['ID']}: {class_data['Class Name']} ({class_data['Color Code']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982940ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RESTORE+ default scheme\n",
    "scheme_name = \"RESTORE+ Project\"\n",
    "success, message = manager.load_default_scheme(scheme_name)\n",
    "\n",
    "if success:\n",
    "    print(f\"✅ {message}\")\n",
    "else:\n",
    "    print(f\"❌ {message}\")\n",
    "\n",
    "# Display the loaded scheme\n",
    "display_classification_scheme(manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc2278",
   "metadata": {},
   "source": [
    "### System Response 2.2: Download classification scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Export Classification Scheme ===\")\n",
    "#Convert the selected  classification scheme manager to dataframe\n",
    "classification_df = manager.get_dataframe()\n",
    "print(\"Classification DataFrame:\")\n",
    "print(classification_df)\n",
    "#Save the file\n",
    "output_path = '../Selected_LC_Classification_Scheme.csv'\n",
    "classification_df.to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Classification scheme saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449588c3",
   "metadata": {},
   "source": [
    "# Module 3: Generate Region Of Interest\n",
    "Three methods to generate ROI are supported in EPISTEM platform:\n",
    "1. **Upload Training Data** - Upload your own shapefile\n",
    "2. **On-screen Sampling** - Create samples using interactive map\n",
    "3. **Default Reference Data** - Use Epistem's default training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdddc0",
   "metadata": {},
   "source": [
    "## Library Import and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1d02e",
   "metadata": {},
   "source": [
    "## System Response 3.1 Prerequisite Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Checking Prerequisites ===\")\n",
    "#Load from previous module\n",
    "#From Module 1 - AOI data\n",
    "try:\n",
    "    AOI = aoi\n",
    "    print(\"✅ AOI from Module 1 is available\")\n",
    "    aoi_available = True\n",
    "except:\n",
    "    print(\"❌ AOI data not available, please run Module 1 first\")\n",
    "    aoi_available = False\n",
    "\n",
    "#From Module 2 - Classification scheme\n",
    "try:\n",
    "    \n",
    "    # For demonstration, create sample classification scheme\n",
    "    LULCTable = classification_df\n",
    "    print(\"✅ Classification scheme from Module 2 is available\")\n",
    "    print(f\"   - Number of classes: {len(LULCTable)}\")\n",
    "    scheme_available = True\n",
    "except:\n",
    "    print(\"❌ Classification scheme not available, please run Module 2 first\")\n",
    "    scheme_available = False\n",
    "\n",
    "if aoi_available and scheme_available:\n",
    "    print(\"\\n✅ All prerequisites met! You can proceed with training data collection.\")\n",
    "else:\n",
    "    print(\"\\n❌ Prerequisites not met. Please complete previous modules first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cede0c",
   "metadata": {},
   "source": [
    "## System Response 3.2 ROI Upload and content Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae398a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modul 3a \n",
    "# Import modules and functions\n",
    "import ee\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "from epistemx.module_3 import InputCheck, SyncTrainData, SplitTrainData, LULCSamplingTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Data Input -----\n",
    "# 1. Decision to upload data\n",
    "UploadTrainData = True # set as 'true' to upload your own training data shapefile\n",
    "# set as 'false' to either add train data by sampling on screen or use default training data\n",
    "\n",
    "# 2. Training data file path (if UploadTrainData is true)\n",
    "TrainVectPath  = '../test_data/Training_Sumsel_Data.shp'\n",
    "TrainField = 'ID' \n",
    "        # Load and process training data\n",
    "TrainDataDict = SyncTrainData.LoadTrainData(\n",
    "            landcover_df=LULCTable,\n",
    "            aoi_geometry=AOI,\n",
    "            training_shp_path=TrainVectPath\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- System response 3.2.a -----\n",
    "# Set class field\n",
    "TrainDataDict = SyncTrainData.SetClassField(TrainDataDict, TrainField)\n",
    "\n",
    "# Validate classes\n",
    "TrainDataDict = SyncTrainData.ValidClass(TrainDataDict, 1)\n",
    "\n",
    "    # Check sample sufficiency\n",
    "TrainDataDict = SyncTrainData.CheckSufficiency(TrainDataDict, min_samples=20)\n",
    "\n",
    "    # Filter by AOI\n",
    "TrainDataDict = SyncTrainData.FilterTrainAoi(TrainDataDict)\n",
    "\n",
    "    # Create training data table\n",
    "table_df, total_samples, insufficient_df = SyncTrainData.TrainDataRaw(\n",
    "    training_data=TrainDataDict.get('training_data'),\n",
    "    landcover_df=TrainDataDict.get('landcover_df'),\n",
    "    class_field=TrainDataDict.get('class_field'))\n",
    "\n",
    "#Summary result\n",
    "vr = TrainDataDict.get('validation_results', {})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING DATA SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total training points loaded     : {vr.get('total_points', 'N/A')}\")\n",
    "print(f\"Points after class filtering     : {vr.get('points_after_class_filter', 'N/A')}\")\n",
    "print(f\"Valid points (inside AOI)        : {vr.get('valid_points', 'N/A')}\")\n",
    "print(f\"Invalid classes found            : {len(vr.get('invalid_classes', []))}\")\n",
    "print(f\"Points outside AOI               : {len(vr.get('outside_aoi', []))}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "    # --- Display the main table ---\n",
    "if table_df is not None and not table_df.empty:\n",
    "        display_df = table_df.copy()\n",
    "        if 'Percentage' in display_df.columns:\n",
    "            display_df['Percentage'] = display_df['Percentage'].apply(\n",
    "                lambda x: f\"{x:.2f}%\" if isinstance(x, (int, float)) else x\n",
    "            )\n",
    "        display(display_df)\n",
    "else:\n",
    "        print(\"No valid training data available to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16694e",
   "metadata": {},
   "source": [
    "## System Response 3.2 Default ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4869adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Loading default reference training data...\")\n",
    "TrainEePath = 'projects/ee-rg2icraf/assets/Indonesia_lulc_Sample'\n",
    "TrainField = 'kelas'\n",
    "    \n",
    "try:\n",
    "    print(\"Loading reference training data from Earth Engine...\")\n",
    "        \n",
    "        # Load training data\n",
    "    TrainDataDict = SyncTrainData.LoadTrainData(\n",
    "            landcover_df=LULCTable,\n",
    "            aoi_geometry=AOI,\n",
    "            training_ee_path=TrainEePath\n",
    "        )\n",
    "        \n",
    "    print(\"Processing and validating reference data...\")\n",
    "        \n",
    "        # Set class field\n",
    "    TrainDataDict = SyncTrainData.SetClassField(TrainDataDict, TrainField)\n",
    "        \n",
    "        # Validate classes\n",
    "    TrainDataDict = SyncTrainData.ValidClass(TrainDataDict)\n",
    "        \n",
    "        # Check sufficiency\n",
    "    TrainDataDict = SyncTrainData.CheckSufficiency(TrainDataDict, min_samples=20)\n",
    "        \n",
    "        # Filter by AOI\n",
    "    TrainDataDict = SyncTrainData.FilterTrainAoi(TrainDataDict)\n",
    "        \n",
    "        # Create summary table\n",
    "    table_df, total_samples, insufficient_df = SyncTrainData.TrainDataRaw(\n",
    "            training_data=TrainDataDict.get('training_data'),\n",
    "            landcover_df=TrainDataDict.get('landcover_df'),\n",
    "            class_field=TrainDataDict.get('class_field')\n",
    "        )\n",
    "        \n",
    "    print(\"✅ Reference training data loaded and processed successfully!\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "        \n",
    "        # Display summary table\n",
    "    display(table_df)\n",
    "        \n",
    "        # Store final training data\n",
    "    TrainDataFinal = TrainDataDict.get('training_data')\n",
    "        \n",
    "        # Show validation results\n",
    "    vr = TrainDataDict.get('validation_results', {})\n",
    "    print(f\"\\nValidation Results:\")\n",
    "    print(f\"- Total points loaded: {vr.get('total_points', 'N/A')}\")\n",
    "    print(f\"- Points after class filter: {vr.get('points_after_class_filter', 'N/A')}\")\n",
    "    print(f\"- Valid points (within AOI): {vr.get('valid_points', 'N/A')}\")\n",
    "    print(f\"- Invalid classes: {len(vr.get('invalid_classes', []))}\")\n",
    "        \n",
    "except Exception as e:\n",
    "        print(f\"❌ Error loading reference data: {e}\")\n",
    "        TrainDataFinal = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d699a4",
   "metadata": {},
   "source": [
    "# Module 4: Region of Interest Separability Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d17795",
   "metadata": {},
   "source": [
    "## Library Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1785681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the sample quality functions\n",
    "from epistemx.module_4 import sample_quality\n",
    "from epistemx.module_4_part2 import spectral_plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1fdf5b",
   "metadata": {},
   "source": [
    "## System Response 4.1 Computing Separability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_path = '../test_data/Training_Sumsel_Data.shp'\n",
    "labeled_roi = geemap.shp_to_ee('../test_data/Training_Sumsel_Data.shp')\n",
    "# labeled_roi = geemap.geemap.gdf_to_ee(TrainDataFinal)\n",
    "\n",
    "#Conduct the analysis\n",
    "analyzer = sample_quality(training_data=labeled_roi, \n",
    "    image= stacked_landsat, \n",
    "    class_property='ID',           # Column with numeric IDs (1, 2, 3, etc.)\n",
    "    region= aoi,\n",
    "    class_name_property='LC_Name'          # Column with names ('Forest', 'Urban', 'Water', etc.)\n",
    ")\n",
    "# Extract spectral values\n",
    "pixel_extract = analyzer.extract_spectral_values(scale=30, max_pixels_per_class=5000)\n",
    "samples_statistic = analyzer.sample_stats()\n",
    "sample_df = analyzer.get_sample_stats_df()\n",
    "display(sample_df)\n",
    "#Sample statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample statistic (pixel value extracted from the imagery)\n",
    "pixel_stats = analyzer.sample_pixel_stats(pixel_extract)\n",
    "pixel_stats_df = analyzer.get_sample_pixel_stats_df(pixel_extract)\n",
    "display(pixel_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8effda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform separability Analysis (iether using Transformed Divergence or Jeffries Matutista )\n",
    "separability_analysis = analyzer.get_separability_df(pixel_extract, method='TD')\n",
    "display(separability_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dad481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the lowest separability\n",
    "lowest_sep = analyzer.lowest_separability(pixel_extract)\n",
    "display(lowest_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall separability summary\n",
    "sep_summary = analyzer.sum_separability(pixel_extract)\n",
    "print(\"Overall Separability Statistics:\")\n",
    "display(sep_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d291b",
   "metadata": {},
   "source": [
    "## System Response 4.2 Sample Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d23c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box plot to detect outlier\n",
    "ploter = spectral_plotter(analyzer)\n",
    "box = ploter.plot_boxplot(pixel_extract)\n",
    "for fig in box:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#static scatter plot\n",
    "stat_plot = ploter.static_scatter_plot(pixel_extract, x_band='NIR', y_band='RED', add_ellipse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21da65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D scatter plot\n",
    "multi_d_scater = ploter.scatter_plot_3d(pixel_extract)\n",
    "multi_d_scater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4302b3",
   "metadata": {},
   "source": [
    "# Module 6: Land Cover Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6182fbfa",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac11b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epistemx.module_6_phase1 import FeatureExtraction, Generate_LULC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da710a2",
   "metadata": {},
   "source": [
    "## System Response 6.2 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Training Test Split\n",
    "features = FeatureExtraction()\n",
    "strafied_train, stratified_test = features.stratified_split(labeled_roi, stacked_landsat, \n",
    "                            class_prop='ID', train_ratio=0.5)\n",
    "classifier = Generate_LULC()\n",
    "print(\"Performing Classification...\")\n",
    "#Multiclass hard classification\n",
    "classification_map, trained_model = generate_eval_lulc.hard_classification(strafied_train, class_property='ID', image=stacked_landsat,\n",
    "                                                          ntrees=300, min_leaf=2, return_model=True)\n",
    "# Evaluate model performance\n",
    "print(\"Evaluating model performance...\")\n",
    "\n",
    "try:\n",
    "    accuracy_metrics = classifier.evaluate_model(\n",
    "        trained_model=trained_model,\n",
    "        test_data=stratified_test,\n",
    "        class_property='ID'\n",
    "    )\n",
    "    \n",
    "    print(\"✓ Model evaluation completed\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in model evaluation: {e}\")                                                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49859f",
   "metadata": {},
   "source": [
    "## System Response 6.3 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accuracy results\n",
    "print(\"=== Model Performance Summary ===\")\n",
    "print(f\"Overall Accuracy: {accuracy_metrics['overall_accuracy']:.4f} ({accuracy_metrics['overall_accuracy']*100:.2f}%)\")\n",
    "print(f\"Kappa Coefficient: {accuracy_metrics['kappa']:.4f}\")\n",
    "print(f\"Overall G-Mean: {accuracy_metrics['overall_gmean']:.4f}\")\n",
    "\n",
    "print(\"\\n=== Per-Class Metrics ===\")\n",
    "#Class Dataframe\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': accuracy_metrics['precision'],\n",
    "    'Recall': accuracy_metrics['recall'],\n",
    "    'F1-Score': accuracy_metrics['f1_scores'],\n",
    "    'G-Mean': accuracy_metrics['gmean_per_class']\n",
    "})\n",
    "\n",
    "# Round to 4 decimal places\n",
    "metrics_df = metrics_df.round(4)\n",
    "\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e88e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "confusion_matrix = np.array(accuracy_metrics['confusion_matrix'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7077f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "print(\"Analyzing feature importance...\")\n",
    "\n",
    "try:\n",
    "    importance_df = classifier.get_feature_importance(trained_model)\n",
    "    print(\"✓ Feature importance analysis completed\")\n",
    "    \n",
    "    display(importance_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in feature importance analysis: {e}\")\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create bar plot\n",
    "bars = plt.bar(importance_df['Band'], importance_df['Importance (%)'])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, importance_df['Importance (%)']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "             f'{value:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Feature Importance by Spectral Band')\n",
    "plt.xlabel('Landsat 8 Bands')\n",
    "plt.ylabel('Importance (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b2adb",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ab3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Classification Scheme ===\n",
    "scheme = pd.read_csv(\"../Selected_LC_Classification_Scheme.csv\")\n",
    "palette = scheme[\"Color Palette\"].tolist()\n",
    "classes = scheme[\"Land Cover Class\"].tolist()\n",
    "ids = scheme[\"ID\"].tolist()\n",
    "\n",
    "# === Visualization Parameters ===\n",
    "vis_params = {\n",
    "    \"min\": min(ids),\n",
    "    \"max\": max(ids),\n",
    "    \"palette\": palette\n",
    "}\n",
    "\n",
    "# === Create geemap Map ===\n",
    "Map = geemap.Map() \n",
    "Map.centerObject(aoi, 7)\n",
    "Map.addLayer(classification_map, vis_params, \"LULC Classification\")\n",
    "\n",
    "# === Add Legend ===\n",
    "Map.add_legend(\n",
    "    title=\"Land Cover Classification\",\n",
    "    labels=classes,\n",
    "    colors=palette\n",
    ")\n",
    "\n",
    "# Display\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c0377",
   "metadata": {},
   "source": [
    "# Module 7: Thematic Accuracy Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad7a4dc",
   "metadata": {},
   "source": [
    "## System Response 7.3 Thematic Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epistemx.module_7 import Thematic_Accuracy_Assessment\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "# Initialize the accuracy assessment class\n",
    "accuracy_assessor = Thematic_Accuracy_Assessment()\n",
    "print(\"✓ Thematic Accuracy Assessment class initialized\")\n",
    "print(f\"Supported metrics: {accuracy_assessor.supported_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f505ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = geemap.shp_to_ee(\"../test_data\\Evaluation_Sumsel_data.shp\") \n",
    "\n",
    "# === 2. Create Assessment Object ===\n",
    "assessor = Thematic_Accuracy_Assessment()\n",
    "\n",
    "# === 3. Run Accuracy Assessment ===\n",
    "success, results = assessor.run_accuracy_assessment(\n",
    "    lcmap=classification_map,\n",
    "    validation_data=validation_data,\n",
    "    class_property='LULC_ID',   #Validation ID column\n",
    "    scale=30\n",
    ")\n",
    "\n",
    "# === 4. Display Results ===\n",
    "if success:\n",
    "    print(\"=== Thematic Accuracy Results ===\")\n",
    "    summary = assessor.format_accuracy_summary(results)\n",
    "    print(\"Overall Accuracy :\", summary['overall_accuracy'])\n",
    "    print(\"Kappa Coefficient:\", summary['kappa'])\n",
    "    print(\"95% CI          :\", summary['confidence_interval'])\n",
    "    print(\"Samples Used     :\", summary['sample_size'])\n",
    "else:\n",
    "    print(\"Error:\", results[\"error\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
